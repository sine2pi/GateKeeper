import torch
import torch.nn as nn
import torch.nn.functional as F

class Gatekeeper(nn.Module):
    """
    Controls information flow between neural network components.
    
    Like Charon of Greek mythology, this module decides which information
    crosses between processing stages, maintaining efficiency by selectively
    processing only important tokens and layers.
    """
    def __init__(self, dims, total_layers=12, sparsity_threshold=0.2):
        super().__init__()
        self.dims = dims
        self.total_layers = total_layers
        self.sparsity_threshold = sparsity_threshold
        
        # Token importance prediction
        self.importance_predictor = nn.Sequential(
            nn.LayerNorm(dims),
            nn.Linear(dims, 128),
            nn.GELU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
        
        # Layer traversal policy
        self.policy_net = nn.Sequential(
            nn.Linear(dims, 128),
            nn.ReLU(),
            nn.Linear(128, 3)  # 3 actions: normal, skip, jump
        )
        
        # Working memory controller
        self.memory_controller = nn.Sequential(
            nn.LayerNorm(dims),
            nn.Linear(dims, 1),
            nn.Sigmoid()
        )
        
        # Working memory
        self.working_memory = nn.Parameter(torch.zeros(1, 1, dims))
        
        # Skip/jump weights for residual connections
        self.jump_weights = nn.Parameter(torch.tensor([0.7, 0.3, 0.1]))
        
    def forward(self, x, current_layer, return_stats=False):
        """
        Determine processing path and token importance.
        
        Args:
            x: Input tensor [batch, seq_len, dims]
            current_layer: Current layer index
            return_stats: Whether to return computation statistics
            
        Returns:
            - Token importance mask [batch, seq_len, 1]
            - Layer decision (0=normal, 1=skip, 2=jump)
            - Jump distance (if decision is jump)
            - Updated working memory
            - Statistics (if return_stats=True)
        """
        batch, seq_len = x.shape[:2]
        
        # Predict token importance
        token_importance = self.importance_predictor(x)
        importance_mask = (token_importance > self.sparsity_threshold).float()
        
        # Get policy for layer traversal
        pooled = x.mean(dim=1)
        policy_logits = self.policy_net(pooled)
        policy = F.softmax(policy_logits, dim=-1)
        
        # Make decision (normal, skip, jump)
        if current_layer >= self.total_layers - 1:
            # No skipping at the last layer
            decision = 0
            jump_dist = 1
        else:
            if torch.rand(1).item() < 0.1:  # Exploration
                decision = torch.randint(0, 3, (1,)).item()
            else:  # Exploitation
                decision = torch.argmax(policy, dim=-1)[0].item()
                
            # Determine jump distance if needed
            if decision == 2:  # Jump
                jump_dist = torch.randint(2, min(5, self.total_layers - current_layer), (1,)).item()
            else:
                jump_dist = 1 if decision == 0 else 2  # Normal or skip
        
        # Update working memory with current state
        memory_gate = self.memory_controller(x.mean(dim=1, keepdim=True))
        working_memory = self.working_memory.expand(batch, -1, -1)
        updated_memory = memory_gate * working_memory + (1 - memory_gate) * x.mean(dim=1, keepdim=True)
        
        if return_stats:
            stats = {
                'token_importance_mean': token_importance.mean().item(),
                'decision': decision,
                'jump_distance': jump_dist,
                'memory_gate': memory_gate.mean().item()
            }
            return importance_mask, decision, jump_dist, updated_memory, stats
        
        return importance_mask, decision, jump_dist, updated_memory
    
# Usage examples:

# def forward(self, x):
#     batch, seq_len = x.shape[:2]
#     layer_idx = 0
#     original_x = x
#     working_memory = self.init_memory(batch)
    
#     # Process through layers with gatekeeper
#     while layer_idx < self.num_layers:
#         # Ask the gatekeeper what to do
#         importance_mask, decision, jump_dist, working_memory = self.gatekeeper(
#             x, layer_idx)
        
#         if decision == 1:  # Skip
#             layer_idx += 1
#             continue
            
#         if decision == 2:  # Jump
#             # Apply weighted residual before jumping
#             jump_weight = self.gatekeeper.jump_weights[min(jump_dist-1, 2)]
#             x = x + jump_weight * original_x + (1-jump_weight) * working_memory
#             layer_idx += jump_dist
#             continue
        
#         # Normal processing with token importance
#         layer = self.layers[layer_idx]
        
#         # Only process important tokens
#         if importance_mask.mean() > 0.1:
#             # Apply attention with importance mask
#             norm_x = layer.norm1(x)
#             attn_out = layer.attention(norm_x, mask=importance_mask)
#             x = x + importance_mask * attn_out
            
#             # Update working memory
#             working_memory = self.update_memory(x, working_memory)
        
#         layer_idx += 1
    
#     return x

# class NeuralNetworkWithGatekeeper(nn.Module):
#     def __init__(self, dims, num_layers=12):
#         super().__init__()
#         self.dims = dims
#         self.num_layers = num_layers
#         self.gatekeeper = NeuralGatekeeper(dims, total_layers=num_layers)
        
#         # Define layers (e.g., Transformer blocks)
#         self.layers = nn.ModuleList([
#             nn.TransformerEncoderLayer(d_model=dims, nhead=8) for _ in range(num_layers)
#         ])
        
#     def init_memory(self, batch_size):
#         return torch.zeros(batch_size, 1, self.dims).to(next(self.parameters()).device)
    
#     def update_memory(self, x, working_memory):
#         return (x + working_memory) / 2  # Simple averaging for memory update`
